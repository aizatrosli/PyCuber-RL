{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from core.rlCuber import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation = 48 \n",
      "Action = 6 \n"
     ]
    }
   ],
   "source": [
    "env = rlcuber()\n",
    "print(\"Observation = {} \".format(env.observation_space.n))\n",
    "print(\"Action = {} \".format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== new episode =====\n",
      "         [g][r][g]\n",
      "         [w][y][w]\n",
      "         [w][b][y]\n",
      "[r][o][r][b][o][g][o][b][w][o][w][y]\n",
      "[g][r][o][g][g][y][o][o][r][b][b][r]\n",
      "[b][g][o][y][g][r][g][y][o][b][y][r]\n",
      "         [b][y][w]\n",
      "         [w][w][r]\n",
      "         [y][b][w]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][g][y]\n",
      "         [w][y][b]\n",
      "         [r][o][g]\n",
      "[o][o][g][y][y][r][w][y][o][b][r][b]\n",
      "[r][r][g][y][g][b][w][o][w][g][b][y]\n",
      "[y][r][w][b][o][y][o][r][g][o][o][b]\n",
      "         [r][g][g]\n",
      "         [b][w][w]\n",
      "         [r][b][w]\n",
      "\n",
      "===== new episode =====\n",
      "         [b][b][b]\n",
      "         [w][y][y]\n",
      "         [o][r][g]\n",
      "[r][g][y][g][b][r][w][r][y][o][y][w]\n",
      "[b][r][r][g][g][b][o][o][y][o][b][w]\n",
      "[r][o][g][o][y][w][o][r][g][r][o][y]\n",
      "         [w][g][b]\n",
      "         [g][w][w]\n",
      "         [b][w][y]\n",
      "\n",
      "===== new episode =====\n",
      "         [y][b][y]\n",
      "         [g][y][o]\n",
      "         [b][w][r]\n",
      "[g][y][r][y][o][b][w][y][g][o][r][r]\n",
      "[b][r][r][w][g][b][w][o][r][g][b][o]\n",
      "[y][g][o][w][g][r][g][b][o][b][y][o]\n",
      "         [g][o][w]\n",
      "         [w][w][y]\n",
      "         [b][r][w]\n",
      "\n",
      "===== new episode =====\n",
      "         [g][w][y]\n",
      "         [y][y][o]\n",
      "         [o][r][r]\n",
      "[o][b][y][g][g][g][y][b][o][b][b][w]\n",
      "[w][r][y][r][g][g][y][o][r][b][b][g]\n",
      "[g][o][b][y][r][w][b][o][w][o][g][r]\n",
      "         [r][w][r]\n",
      "         [w][w][y]\n",
      "         [w][o][b]\n",
      "\n",
      "===== new episode =====\n",
      "         [y][b][b]\n",
      "         [b][y][o]\n",
      "         [g][w][g]\n",
      "[g][r][w][o][o][o][y][y][o][w][y][r]\n",
      "[w][r][b][o][g][r][w][o][g][o][b][b]\n",
      "[b][w][g][w][y][r][w][y][y][b][g][r]\n",
      "         [r][r][b]\n",
      "         [g][w][g]\n",
      "         [y][r][o]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][r][r]\n",
      "         [o][y][o]\n",
      "         [o][r][b]\n",
      "[r][w][y][g][y][r][y][g][g][y][b][g]\n",
      "[y][r][b][y][g][g][w][o][o][y][b][g]\n",
      "[w][w][b][o][o][w][b][r][b][w][w][o]\n",
      "         [y][b][r]\n",
      "         [b][w][g]\n",
      "         [g][r][o]\n",
      "\n",
      "===== new episode =====\n",
      "         [g][r][r]\n",
      "         [w][y][y]\n",
      "         [b][g][w]\n",
      "[r][o][y][o][w][r][b][g][w][g][g][y]\n",
      "[r][r][o][y][g][o][b][o][y][b][b][b]\n",
      "[y][r][g][y][g][o][b][r][o][w][w][b]\n",
      "         [o][o][w]\n",
      "         [y][w][w]\n",
      "         [r][b][g]\n",
      "\n",
      "===== new episode =====\n",
      "         [o][g][b]\n",
      "         [b][y][b]\n",
      "         [r][g][b]\n",
      "[g][w][g][y][r][y][o][o][o][w][o][y]\n",
      "[y][r][r][b][g][b][y][o][o][w][b][r]\n",
      "[b][o][y][r][w][w][g][g][r][g][g][w]\n",
      "         [b][r][o]\n",
      "         [y][w][y]\n",
      "         [r][w][w]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][o][r]\n",
      "         [o][y][g]\n",
      "         [o][y][w]\n",
      "[o][w][b][y][r][o][g][o][y][b][b][b]\n",
      "[y][r][y][g][g][r][g][o][w][b][b][o]\n",
      "[y][w][w][b][r][g][w][y][y][g][g][g]\n",
      "         [r][b][r]\n",
      "         [r][w][b]\n",
      "         [o][w][r]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][o][y]\n",
      "         [o][y][r]\n",
      "         [y][g][r]\n",
      "[r][g][b][r][y][b][w][g][o][b][y][g]\n",
      "[w][r][w][b][g][w][r][o][r][y][b][o]\n",
      "[y][b][g][y][y][o][w][b][b][w][w][r]\n",
      "         [o][b][g]\n",
      "         [o][w][r]\n",
      "         [g][g][o]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][o][r]\n",
      "         [b][y][w]\n",
      "         [b][g][r]\n",
      "[g][y][r][y][y][b][w][r][g][y][y][o]\n",
      "[g][r][r][b][g][r][g][o][o][w][b][w]\n",
      "[b][o][o][g][w][r][g][g][b][w][r][y]\n",
      "         [y][b][w]\n",
      "         [b][w][o]\n",
      "         [o][y][o]\n",
      "\n",
      "===== new episode =====\n",
      "         [o][o][w]\n",
      "         [b][y][g]\n",
      "         [g][w][g]\n",
      "[b][o][r][w][r][w][o][o][r][b][w][w]\n",
      "[y][r][w][b][g][y][r][o][b][y][b][o]\n",
      "[o][w][y][r][r][g][y][r][y][g][g][b]\n",
      "         [b][b][o]\n",
      "         [g][w][g]\n",
      "         [y][y][r]\n",
      "\n",
      "===== new episode =====\n",
      "         [w][r][r]\n",
      "         [b][y][o]\n",
      "         [w][g][y]\n",
      "[g][y][r][b][o][o][b][w][g][y][g][o]\n",
      "[w][r][o][y][g][y][r][o][y][g][b][r]\n",
      "[y][w][w][o][b][w][r][w][y][o][o][b]\n",
      "         [b][r][g]\n",
      "         [b][w][g]\n",
      "         [r][b][g]\n",
      "\n",
      "===== new episode =====\n",
      "         [g][g][o]\n",
      "         [r][y][y]\n",
      "         [o][b][y]\n",
      "[o][y][w][b][y][o][b][o][y][g][y][w]\n",
      "[g][r][r][b][g][g][o][o][w][o][b][r]\n",
      "[r][w][b][y][r][r][g][g][y][g][o][b]\n",
      "         [r][w][w]\n",
      "         [b][w][w]\n",
      "         [w][b][r]\n",
      "\n",
      "===== new episode =====\n",
      "         [r][y][g]\n",
      "         [y][y][o]\n",
      "         [w][w][w]\n",
      "[y][o][b][o][b][r][b][w][o][y][b][g]\n",
      "[o][r][r][y][g][b][r][o][r][g][b][b]\n",
      "[b][w][w][r][w][w][g][o][o][y][y][r]\n",
      "         [g][g][o]\n",
      "         [r][w][g]\n",
      "         [y][g][b]\n",
      "\n",
      "===== new episode =====\n",
      "         [b][r][w]\n",
      "         [b][y][r]\n",
      "         [y][y][b]\n",
      "[w][w][r][g][b][y][o][w][o][g][g][o]\n",
      "[y][r][r][b][g][g][o][o][y][r][b][o]\n",
      "[o][g][g][w][b][r][b][w][b][r][y][y]\n",
      "         [r][o][y]\n",
      "         [w][w][o]\n",
      "         [g][g][w]\n",
      "\n",
      "===== new episode =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-315ecbe0f0e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mj\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#Choose an action by greedily (with noise) picking from Q table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m#Get new state and reward from environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# Set learning parameters\n",
    "learningrate = .625\n",
    "discountfactor = .9\n",
    "num_episodes = 50000\n",
    "rewardList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    print(\"===== new episode =====\")\n",
    "    rewardAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    shigh = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 999:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        a =np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        print(\"Action = {}\".format(a))\n",
    "        #Get new state and reward from environment\n",
    "        s1,r,d = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + learningrate*(r + discountfactor*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rewardAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    rewardList.append(rewardAll)\n",
    "    env.render()\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
